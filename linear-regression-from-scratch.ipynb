{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><span style=\"color:crimson;\"><span style=\"font-size:50px;\">LINEAR REGRESSION FROM SCRATCH</span>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"<span style=\"font-size:40px;\">TABLE OF CONTENTS:</span>\n\n* <span style=\"font-size:30px;\">What is Linear Regression</span>\n* <span style=\"font-size:30px;\">R2 & Adjusted R2</span>\n* <span style=\"font-size:30px;\">WORKING ON S SAMPLE DATASET</span>\n* <span style=\"font-size:30px;\">What is Multiple Linear Regression</span>\n* <span style=\"font-size:30px;\">Multi-Colinearity</span>","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"<center><b><span style=\"font-size:30px;\">WHAT IS LINEAR REGRESSION ? \n    \n    \n![](https://littleml.files.wordpress.com/2019/03/introduction_linear.jpg)    ","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:24px;\">Linear Regression is one of the most fundamental and widely known Machine Learning Algorithms which people start with. Building blocks of a Linear Regression Model are:\n\n* <span style=\"font-size:22px;\">Discreet/continuous independent variables\n\n* <span style=\"font-size:22px;\">A best-fit regression line\n\n* <span style=\"font-size:22px;\">Continuous dependent variable. i.e., A Linear Regression model predicts the dependent variable using a regression line based on the independent variables. The equation of the Linear Regression is:\n    \n<center><span style=\"font-size:20px;\">Y= ùõΩ1x + ùõΩ0</center>\n    \n* <span style=\"font-size:20px;\">ùõΩ0  and  ùõΩ1  are the model coefficients. To create a model, we must \"learn\" the values of these coefficients. And once we have the value of these coefficients, we can use the model to predict the Target Feature.\n    \n\n## UNDERLYING ASSUMPTIONS\n    \n* <span style=\"font-size:20px;\">The regression model is linear in terms of coefficients and error term.\n    \n* <span style=\"font-size:20px;\">The mean of the residuals is zero.\n* <span style=\"font-size:20px;\">The error terms are not correlated with each other, i.e. given an error value; we cannot predict the next error value.\n* <span style=\"font-size:20px;\">The independent variables(x) are uncorrelated with the residual term, also termed as exogeneity. This, in layman term, generalises that in no way should the error term be predicted given the value of independent variables.\n* <span style=\"font-size:20px;\">The error terms have a constant variance, i.e. homoscedasticity.\n* <span style=\"font-size:20px;\">No Multicollinearity, i.e. no independent variables should be correlated with each other or affect one another. If there is multicollinearity, the precision of prediction by the OLS model decreases.\n* <span style=\"font-size:20px;\">The error terms are normally distributed.</span>\n    \n    \n## How Do you Know this is the best fit line? \n\n<span style=\"font-size:20px;\">The best fit line is obtained by minimizing the residual. Residual is the distance between the actual Y and the predicted Y.</span>\n    \n## How Well Does the Model Fit the data?\n\n<span style=\"font-size:20px;\">One of the most generic way to evaluate the fit of a linear model is by computing the R-squared value.</span>","metadata":{}},{"cell_type":"markdown","source":"-----","metadata":{}},{"cell_type":"markdown","source":"<center><b><span style=\"font-size:30px;\">R2 & ADJUSTED R2","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:26px;\"><b>R-SQUARE:</b>\n\n* <span style=\"font-size:24px;\">R-squared, also known as the coefficient determination, defines the degree to which the variance in the dependent variable (or target) can be explained by the independent variable (features).\n* <span style=\"font-size:24px;\">It lies between value 0 and 1.\n* <span style=\"font-size:24px;\">For example, ùëÖ2 statistic = 0.75, it says that our model fits 75 % of the total data set.\n* <span style=\"font-size:24px;\">So, in simple terms, higher the R squared, the more variation is explained by your input variables and hence better is your model.\n* <span style=\"font-size:24px;\">The R-squared is calculated by dividing sum of squares of residuals from the regression model (given by RSS) by total sum of squares of errors from the average model (given by TSS) and then subtract it from 1.\n\n<center><span style=\"color:crimson;\"><span style=\"font-size:24px;\">R2 = 1 - RSS/TSS</center>\n\n* <span style=\"font-size:24px;\">One drawback of r-squared is that it assumes every variable helps in explaining the variation in the target, which might not always be true. For instance, if we add a new features to the data (which may or may not be useful), the r-squared value for the model would either increase or remain same but it would never decrease.\n    \n<span style=\"font-size:26px;\"><b>ADJUSTED R-SQUARE:</b>\n    \n* <span style=\"font-size:24px;\">To rectify this DRAWBACK, we use Adjusted R2 value which penalises excessive use of such features which do not correlate with the output data.\n    \n<center><span style=\"color:crimson;\"><span style=\"font-size:24px;\">Adjusted R2 = 1 - ([1-R2][N-1])/(N-P-1)</center>","metadata":{}},{"cell_type":"markdown","source":"-----","metadata":{}},{"cell_type":"markdown","source":"<center><b><span style=\"font-size:30px;\">SIMPLE LINEAR REGRESSION IMPLEMENTATION","metadata":{}},{"cell_type":"markdown","source":"## PROBLEM STATEMENT: \n\n<span style=\"font-size:24px;\">THE DATASET CONSISTS OF TWO COLUMNS - EXPERIENCE AND SALARY(TARGET VARIABLE).\n    \n##### SOURCE : KRISH NAIK SIR.","metadata":{}},{"cell_type":"code","source":"#IMPORT REQUIRED LIBRARIES:\n\n# necessary Imports\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pickle","metadata":{"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/random-salary-data-of-employes-age-wise/Salary_Data.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"   YearsExperience   Salary\n0              1.1  39343.0\n1              1.3  46205.0\n2              1.5  37731.0\n3              2.0  43525.0\n4              2.2  39891.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YearsExperience</th>\n      <th>Salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.1</td>\n      <td>39343.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.3</td>\n      <td>46205.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.5</td>\n      <td>37731.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>43525.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.2</td>\n      <td>39891.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = df.iloc[:, :-1].values\ny = df.iloc[:, 1].values","metadata":{"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)","metadata":{"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# Fitting Simple Linear Regression to the Training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = regressor.predict(X_test)","metadata":{"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# Visualising the Training set results\nplt.scatter(X_train, y_train, color = 'red')\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\n\n\n# Visualising the Test set results\nplt.scatter(X_test, y_test, color = 'red')\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Salary vs Experience (Test set)')\nplt.xlabel('Years of Experience')\nplt.ylabel('Salary')\nplt.show()","metadata":{"trusted":true},"execution_count":76,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"<span style=\"font-size:30px;\">THIS FIGURE SHOW THE BEST FIT LINE ON THIS DATASET. THIS IS HOW THE REGRESSION MODEL WORKS.","metadata":{}},{"cell_type":"code","source":"#LET US CALCULATE THE R2 VALUE:\nprint(\"Coefficient of determination R^2 <-- on train set: {}\".format(regressor.score(X_train, y_train)))\n\nprint(\"Coefficient of determination R^2 <-- on test set: {}\".format(regressor.score(X_test, y_test)))","metadata":{"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Coefficient of determination R^2 <-- on train set: 0.9381900012894278\nCoefficient of determination R^2 <-- on test set: 0.9749154407708353\n","output_type":"stream"}]},{"cell_type":"markdown","source":"----------------------------","metadata":{}},{"cell_type":"markdown","source":"\n    \n![](https://i.morioh.com/2020/04/14/74bd389a2f28.jpg)","metadata":{}},{"cell_type":"markdown","source":"* <span style=\"font-size:24px;\">The steps to perform simple and multiple linear regression are almost the same, the difference lies in the Evaluation.\n* <span style=\"font-size:24px;\">In Multiple Regression we use more than one feature for predicting the Target Variable.","metadata":{}},{"cell_type":"markdown","source":"<center><b><span style=\"font-size:30px;\">MULTIPLE LINEAR REGRESSION IMPLEMENTATION","metadata":{}},{"cell_type":"code","source":"#IMPORT REQUIRED LIBRARIES:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","metadata":{"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/various-expenses-and-the-profits-of-50-startups/50_Startups.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"   R&D Spend  Administration  Marketing Spend       State     Profit\n0  165349.20       136897.80        471784.10    New York  192261.83\n1  162597.70       151377.59        443898.53  California  191792.06\n2  153441.51       101145.55        407934.54     Florida  191050.39\n3  144372.41       118671.85        383199.62    New York  182901.99\n4  142107.34        91391.77        366168.42     Florida  166187.94","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>R&amp;D Spend</th>\n      <th>Administration</th>\n      <th>Marketing Spend</th>\n      <th>State</th>\n      <th>Profit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>165349.20</td>\n      <td>136897.80</td>\n      <td>471784.10</td>\n      <td>New York</td>\n      <td>192261.83</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>162597.70</td>\n      <td>151377.59</td>\n      <td>443898.53</td>\n      <td>California</td>\n      <td>191792.06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>153441.51</td>\n      <td>101145.55</td>\n      <td>407934.54</td>\n      <td>Florida</td>\n      <td>191050.39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>144372.41</td>\n      <td>118671.85</td>\n      <td>383199.62</td>\n      <td>New York</td>\n      <td>182901.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>142107.34</td>\n      <td>91391.77</td>\n      <td>366168.42</td>\n      <td>Florida</td>\n      <td>166187.94</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = df.iloc[:, :-1]\ny = df.iloc[:, 4]","metadata":{"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"#Convert the column into categorical columns\n\nstates=pd.get_dummies(X['State'],drop_first=True)","metadata":{"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# Drop the state coulmn\nX=X.drop('State',axis=1)\n\n# concat the dummy variables\nX=pd.concat([X,states],axis=1)","metadata":{"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","metadata":{"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# Fitting Multiple Linear Regression to the Training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = regressor.predict(X_test)\n\nfrom sklearn.metrics import r2_score\nscore=r2_score(y_test,y_pred)\nprint(score)","metadata":{"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"0.9347068473282423\n","output_type":"stream"}]},{"cell_type":"markdown","source":"-----------","metadata":{}},{"cell_type":"markdown","source":"<center><b><span style=\"font-size:30px;\">MULTI-COLINEARITY","metadata":{}},{"cell_type":"markdown","source":"* <span style=\"font-size:22px;\">Multicollinearity occurs when there are two or more independent variables in a multiple regression model, which have a high correlation among themselves. When some features are highly correlated, we might have difficulty in distinguishing between their individual effects on the dependent variable.\n\n* <span style=\"font-size:22px;\">The word multi-collinearity consists of two words:Multi, meaning multiple, and Collinear, meaning being linearly dependent on each other.\n\n* <span style=\"font-size:22px;\">For e.g., Let‚Äôs consider this equation  <b>ùëé+ùëè=1=>ùëè=1‚àíùëé</b>. It means that ‚Äòb‚Äô can be represented in terms of ‚Äòa‚Äô i.e., if the value of ‚Äòa‚Äô changes, automatically the value of ‚Äòb‚Äô will also change. This equation denotes a simple linear relationship among two variables.\n\n* <span style=\"font-size:22px;\">We can define multi-collinearity as the situation where the independent variables (or the predictors) have strong correlation amongst themselves.\n\n* <span style=\"font-size:22px;\">TYPES OF CORRELATION:\n                        1. High Correlation: 0.5 to 1.0 or -0.5 to 1.0\n                        2. Medium Corr     : 0.3 to 0.5 or -0.3 to 0.5\n                        3. Low Correlation : 0.1 to 0.3 or -0.1 to 0.3\n    \n    \n* <span style=\"font-size:22px;\">How we can DETECT Multi-Colinearity:\n    \n    * <span style=\"font-size:20px;\">1. Correlation Matrix\n    * <span style=\"font-size:20px;\">2. Variance Inflation Factor = 1 / [1 - R_SQUARE]\n","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:24px;\"><b>FOR IMPLEMENTATION PART YOU CAN REFER BELOW LINK:</b>\n    \n<span style=\"font-size:22px;\">https://www.geeksforgeeks.org/detecting-multicollinearity-with-vif-python/","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"<center><span style=\"font-size:24px;\"><b>CONCLUSION\n    \n-----","metadata":{}},{"cell_type":"markdown","source":"* <span style=\"font-size:24px;\">THIS NOTEBOOK IS CREATED FOR EVERYONE WHO WANTS TO LEARN LINEAR REGRESSION FROM SCRATCH. IN THIS I HAVE EXPLAINED EVERYTHING WITH SAMPLE DATASETS.\n    \n    \n* <span style=\"font-size:24px;\">IN MY NEXT NOTEBOOK I'LL BE CONTINUING THIS NOTEBOOK BY EXPLAINING REGULARIZATION FROM SCRATCH.\n    \n    \n<span style=\"font-size:24px;\"><b>HOPE THIS WILL HELP YOU TO UNDERSTAND. IF YOU HAVE ANY QUERIES PLEASE MENTION THEM IN COMMENT BOX I'LL DEFINITELY ANSWERING THEM.\n    \n    \n    \n<span style=\"font-size:24px;\"><b>IF YOU LIKE AND LEARN FROM THIS, PLEASE GIVE ME AN UPVOTE. THANK YOU !!!","metadata":{}}]}